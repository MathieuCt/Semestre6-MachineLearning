{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projet Machine Learning - L3 Groupe A - 08/05/2023\n",
    "## M. Chantot - P. Bouzard - C. Brun "
   ],
   "metadata": {
    "id": "QWFURzr17G2n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wA1cNEXK9FJe"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Algèbre liéaire\n",
    "import pandas as pd # Data rocessig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from scipy import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Montage local à partir de Google Drive\n",
    "# Importation des fichiers .csv\n",
    "# Chemin d'accès aux données dans Google Drive : Placez les données dans un fichier Data dans votre Google Drive\n",
    "Data_X_path = './Data_X.csv'\n",
    "DataNew_X_path = './DataNew_X.csv'\n",
    "Data_Y_path = './Data_Y.csv'\n",
    "\n",
    "# Lecture des fichiers csv avec pandas\n",
    "dfX = pd.read_csv(Data_X_path)\n",
    "dfNX = pd.read_csv(DataNew_X_path)\n",
    "dfY = pd.read_csv(Data_Y_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGzNonXA96No",
    "outputId": "244faf12-1803-47d5-e257-2b0a97bbf34a"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Abandon de l'attribut \"COUNTRY\" qui ne nous servira pas.\n",
    "dfNX = dfNX.drop(['COUNTRY'], axis=1)\n",
    "\n",
    "# Obtention de numpy à partir d'un dataframe pandas\n",
    "Data_X = dfX\n",
    "DataNew_X = dfNX\n",
    "Data_Y = dfY\n",
    "# Affichage des informations des données importées\n",
    "dfX.info()\n",
    "dfNX.info()\n",
    "dfY.info()"
   ],
   "metadata": {
    "id": "sIGfvH2y-8Yk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ad90245-92b1-44e9-9063-7e01766fb20b"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Copie des données pour éviter de détruire les fichiers d'origine\n",
    "Data_X = dfX.copy()\n",
    "Data_NX = dfNX.copy()\n",
    "Data_Y = dfY.copy()\n",
    "\n",
    "# Affichage des 5 premières lignes pour voir si cela a fonctionné\n",
    "Data_X.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "QfnL8ak7AWQk",
    "outputId": "11995515-9142-4953-d27b-db1030a2e6ae"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Data_NX.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "JLYv6LakA7tD",
    "outputId": "d84f346a-9996-45d2-c846-7c4f64094c04"
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Data_Y.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ta7CHh1sBJJ-",
    "outputId": "060c4bfb-da33-4648-c602-80a72fcf83d8"
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## La première étape consiste à nettoyer le jeu de données\n",
    "On retire pour cela les données manquantes, les doublons et les valeurs aberrantes"
   ],
   "metadata": {
    "id": "GXXX6jaMKppg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Vérifier s’il y a des valeurs manquantes dans les données.\n",
    "# Retirer les lignes avec des valeurs manquantes, et les lignes de prix correspondantes\n",
    "# Pour cela, on commence par concaténer les deux jeux de données\n",
    "XY = pd.concat([Data_X,Data_Y], axis=1)\n",
    "XY = XY.drop(['COUNTRY'], axis=1) # On supprime la colonne COUNTRY comme les données à l'interieur sont de STRING, n'étant alors pas intereant à étudier\n",
    "print(\"Data longueur : \", len(XY))\n",
    "# On retire les lignes avec des valeurs manquantes\n",
    "XY = XY.dropna()\n",
    "DataNew_X = DataNew_X.dropna()\n",
    "print(\"Data longueur sans les lignes manquantes: \", len(XY))\n",
    "# On retire les lignes dupliquées\n",
    "XY = XY.drop_duplicates()\n",
    "DataNew_X = DataNew_X.drop_duplicates()\n",
    "print(\"Data longueur sans les lignes dupliquées: \", len(XY))\n",
    "# On cherche maintenant à retirer les valeurs aberrantes\n",
    "print(\"Ecart type des valeurs de XY :\")\n",
    "print(XY.std(numeric_only = True)) # Ecart type avant les valeurs aberrantes\n",
    "XY = XY[(np.abs(stats.zscore(XY)) < 3).all(axis=1)]\n",
    "DataNew_X = DataNew_X[(np.abs(stats.zscore(DataNew_X)) < 3).all(axis=1)]\n",
    "print(\"Data longueur sans les valeurs aberrantes: \", len(XY))\n",
    "# On affiche les valeurs moyennes et les écarts types\n",
    "print(\"Moyenne des valeurs de XY :\")\n",
    "print(XY.mean(numeric_only = True))\n",
    "print(\"Ecart type des valeurs de XY :\")\n",
    "print(XY.std(numeric_only = True)) # Ecart type après les valeurs aberrantes\n",
    "# On sépare ensuite les deux jeux de données\n",
    "Data_X = XY.iloc[:,:-2]\n",
    "Data_Y = XY.iloc[:,-2:]\n",
    "'''\n",
    "print(\"X, : \\n\", Data_X.head())\n",
    "print(\"Y : \\n\", Data_Y.head())\n",
    "'''\n",
    "# Vérifier si les valeurs des différents attributs sont comparables"
   ],
   "metadata": {
    "id": "6vhASXajB098",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "38d4a5c7-4051-4ff9-dbbc-4c5f8f017140"
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "De ce que nous voyons au-dessus, de nombreuses valeurs semblent corrélées, cependant il n'est pas forcément juste de les mettre en relation. Par exemple, mettre en relation les données lié à l'Allemagne entre elle paraît sensé, et comparer certaines mesures entre les deux pays à du sens, alors que de comparé majoritairement les valeurs d'un pays a l'autre ne paraît pas être la meilleure comparaison possible.\n",
    "\n",
    "## Ensuite on prépare le jeu de données\n",
    "Pour cela on procède à une standardisation des données en les ramenant entre 0 et 1\n",
    "\n",
    "Et on calcule la matrice de corrélation pour choisir les variables les plus corrélées au prix"
   ],
   "metadata": {
    "id": "mdpsFwhnLMHj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# On cherche maintenant à trouver les variables les plus corrélées avec le prix\n",
    "# On commence par concaténer les deux jeux de données\n",
    "XY = pd.concat([Data_X,Data_Y], axis=1)\n",
    "# Nous normalisons d'abord les données\n",
    "for column in XY:\n",
    "    XY[column]= (XY[column] - XY[column].mean()) / XY[column].std()\n",
    "corr = XY.corr()\n",
    "Data_X = XY.iloc[:,:-2]\n",
    "Data_Y = XY.iloc[:,-2:]\n",
    "# On affiche la matrice de corrélation\n",
    "'''print(corr)'''\n",
    "# On affiche la matrice de corrélation sous forme de heatmap\n",
    "plt.figure()\n",
    "# Elargir le plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.matshow(corr)\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "ma_OR44p_t4P",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "outputId": "802224d8-6278-4626-efd1-5517d5c11afa"
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# On cherche maintenant à trouver les variables les plus corrélées avec le prix\n",
    "# On affiche les variables les plus corrélées avec le prix\n",
    "print(\"Variables les plus corrélées avec le prix :\")\n",
    "print(np.absolute(corr[\"TARGET\"]).sort_values(ascending=False)[:10])\n",
    "# On prend les 6 valeurs les plus corellées pour faire une regression linéaire"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7I-NYzg_C8ta",
    "outputId": "b3b2495a-4d85-403f-87c0-3a5f991514f6"
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# DE_NET_IMPORT semble être la variable la plus corrélée au prix, on tente donc de représenter cette corrélation sur un scatter plot\n",
    "plt.figure()\n",
    "# Elargir le plot\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(Data_Y[\"TARGET\"],Data_X[\"DE_WINDPOW\"],)\n",
    "# Mettre les titres sur les axes\n",
    "plt.xlabel('DE_WINDPOW', fontweight='bold')\n",
    "plt.ylabel('TARGET', fontweight='bold')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "sTeROpoQG2tB",
    "outputId": "8c9cbc6d-b6a9-4289-80cf-eb1f526c1b80"
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visiblement la corrélation semble limités mais nous ne disposons pas d'autres données pour expliquer le prix\n",
    "### On commence par une regression linéaire simple avec la force du vent en Allemagne (DE_WINDPOW)"
   ],
   "metadata": {
    "id": "fTAieHRXHgQ7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le code effectue une régression linéaire en utilisant le modèle LinearRegression de scikit-learn.\n",
    "\n",
    "La première ligne crée une instance du modèle de régression linéaire.\n",
    "\n",
    "La deuxième ligne utilise la fonction train_test_split de scikit-learn pour diviser les données en un ensemble de formation (X_train et Y_train) et un ensemble de test (X_test et Y_test). La taille de l'ensemble de test est de 20% des données, et le paramètre random_state est défini à 101 pour s'assurer que la division des données est la même à chaque fois que le code est exécuté.\n",
    "\n",
    "La troisième ligne entraîne le modèle de régression linéaire en utilisant les données d'entraînement. Plus précisément, le modèle est entraîné en utilisant les données de la colonne \"DE_NET_EXPORT\" de la variable prédictive Data_X et les données de la colonne \"TARGET\" de la variable cible Data_Y.\n",
    "\n",
    "Enfin, la dernière ligne affiche le coefficient de la pente de la régression linéaire en utilisant la propriété coef_ de l'objet LinearRegression. Ce coefficient représente la relation linéaire entre la variable prédictive et la variable cible."
   ],
   "metadata": {
    "id": "1OYc3t4QRzh0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LR = LinearRegression() # Création d'une instance du modèle de régression linéaire\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data_X,Data_Y, test_size=0.2,random_state=101)\n",
    "LR.fit(pd.DataFrame(X_train[\"DE_NET_EXPORT\"]),pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "print(LR.coef_)"
   ],
   "metadata": {
    "id": "qw-odxFWHuqC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "43b31d88-973e-4428-ba97-a3ff63e06ed7"
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour la deuxième partie de la régression linéaire,\n",
    "\n",
    "La première ligne réalise une prédiction à partir du modèle de régression linéaire entraîné, sur les données de l'ensemble de test. Les prédictions sont effectuées en utilisant les données de la colonne \"DE_NET_EXPORT\" de l'ensemble de test, qui sont passées à la méthode predict du modèle de régression linéaire. Les prédictions sont stockées dans la variable prediction.\n",
    "\n",
    "La deuxième ligne crée une nouvelle figure de taille 4x4 pouces en utilisant la méthode figure de la bibliothèque Matplotlib.\n",
    "\n",
    "La troisième ligne crée un nuage de points en utilisant la méthode scatter de la bibliothèque Matplotlib. Les données de l'ensemble de test sont affichées sur l'axe des abscisses et les prédictions correspondantes sont affichées sur l'axe des ordonnées. La variable cible réelle est représentée par les points bleus."
   ],
   "metadata": {
    "id": "eNytHLuqR7y0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = LR.predict(pd.DataFrame(X_test['DE_NET_EXPORT']))\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(Y_test[\"TARGET\"],prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "s3-O_-d0NAR2",
    "outputId": "42df2aef-dda5-4e7c-eb5e-193279a27653"
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Le résultat de la regression linéaire simple n'est pas très convaincant\n",
    "\n",
    "## Ensuite on essaye avec les 5 variables ayant le plus fort coéfficient de corrélation le plus fort\n"
   ],
   "metadata": {
    "id": "SpnRGA8Remgf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LR = LinearRegression() # Creating an Instance of LinearRegression model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data_X,Data_Y, test_size=0.5,random_state=101)\n",
    "LR.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "print(LR.coef_)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lbNAbexej7N",
    "outputId": "d6c47817-b42d-4ed8-b45b-d1313aff42d9"
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = LR.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(Y_test[\"TARGET\"],prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "U5C67D4MgEPS",
    "outputId": "b2c3a793-5df3-4e73-d21e-fe71e6b01fd5"
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "On n'aboutit pas à des résultats concluants avec une regressionn simple\n",
    "## La regression RIDGE donne d'excellents résultats pour des variables fortement corrélées, ici elle ne le sont pas (mais le sujet nous l'impose quand même)"
   ],
   "metadata": {
    "id": "w9YAv9cdh87V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ridge = Ridge(alpha=2.177999999999871)\n",
    "ridge.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "print(ridge.coef_)\n",
    "prediction = ridge.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(Y_test[\"TARGET\"],prediction)"
   ],
   "metadata": {
    "id": "zG4SQp6Nt3MI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "outputId": "7b9606ab-a01d-4d1a-8846-13c48c9162aa"
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "La première ligne crée une instance du modèle de régression Ridge en fixant le paramètre de régularisation alpha à 1.0.\n",
    "\n",
    "La deuxième ligne entraîne le modèle de régression Ridge en utilisant les données d'entraînement en utilisant les colonnes \"DE_WINDPOW\", \"DE_NET_EXPORT\", \"DE_NET_IMPORT\", \"DE_RESIDUAL_LOAD\", et \"FR_WINDPOW\" de la variable prédictive X_train et les données de la colonne \"TARGET\" de la variable cible Y_train.\n",
    "\n",
    "La troisième ligne affiche les coefficients du modèle de régression Ridge en utilisant la propriété coef_ de l'objet Ridge. Ces coefficients représentent les relations linéaires entre les variables prédictives et la variable cible en tenant compte de la régularisation.\n",
    "\n",
    "La quatrième ligne utilise le modèle entraîné pour effectuer des prédictions sur les données de test en utilisant les mêmes variables prédictives que celles utilisées pour l'entraînement.\n",
    "\n",
    "La cinquième ligne crée une figure avec une taille de 4x4 pouces en utilisant la fonction figure(figsize=(4,4)) de matplotlib.pyplot.\n",
    "\n",
    "La sixième ligne affiche un nuage de points représentant les prédictions par rapport aux valeurs réelles de la variable cible en utilisant la fonction scatter(Y_test[\"TARGET\"],prediction) de matplotlib.pyplot.\n",
    "\n",
    "#Pour le modèle Lasso:"
   ],
   "metadata": {
    "id": "prMoG-nKUWxw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Création d'une instance du modèle de régression Lasso\n",
    "# alpha correspond au coefficient de régularisation\n",
    "lasso = Lasso(alpha=0.00432,)\n",
    "# Entraînement du modèle Lasso sur les données d'entraînement\n",
    "# en utilisant les colonnes sélectionnées pour les variables prédictives et la variable cible\n",
    "lasso.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],\n",
    "           pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "# Affichage des coefficients de la régression Lasso\n",
    "print(lasso.coef_)\n",
    "# Utilisation du modèle Lasso entraîné pour faire des prédictions sur les données de test\n",
    "prediction = lasso.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "# Création d'une figure pour afficher les prédictions\n",
    "plt.figure(figsize=(4,4))\n",
    "# Affichage d'un nuage de points pour comparer les valeurs cibles et les prédictions\n",
    "plt.scatter(Y_test[\"TARGET\"], prediction)"
   ],
   "metadata": {
    "id": "r8G3ubLKxCaq",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "outputId": "4edc8808-3d83-48c7-9946-6d18a27aba1a"
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "  # Pour trouver le meilleur coefficient Alpha pour Ridge et Lasso, on utilise l'algorithme suivant :\n",
    "best_coef = 0\n",
    "a = 0.0\n",
    "best_alpha = 0\n",
    "while a < 3:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "    prediction = ridge.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "    corr_ridge, pval_ridge = spearmanr(Y_test['TARGET'],prediction)\n",
    "    if corr_ridge > best_coef:\n",
    "        best_coef = corr_ridge\n",
    "        best_alpha = a\n",
    "    a += 0.001\n",
    "\n",
    "print(best_coef, best_alpha)\n",
    "# l'interpreteur proposé par google ne permet pas d'obtenir un a convainquant (faute de puissance de calcule)\n",
    "# Après une exécution locale de cette algorithme nous trouvons\n",
    "# a = 2.177999999999871\n",
    "# De même pour le Lasso"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LMA7kYqB1ep",
    "outputId": "087eca58-882a-4e42-c95a-9889ebc54b20"
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les méthodes récemment utilisées fonctionnent bien avec une bonne corrélation entre les paramètres, or celles des données dont nous disposons sont très faibles\n",
    "\n",
    "# Pour les KNN:"
   ],
   "metadata": {
    "id": "WA5Es2WzCc9r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Créer une instance du modèle KNN avec 100 voisins\n",
    "knn_model = KNeighborsRegressor(n_neighbors=100)\n",
    "# Entraîner le modèle KNN en utilisant les données d'entraînement\n",
    "knn_model.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "# Effectuer des prédictions sur les données de test\n",
    "prediction = knn_model.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "# Créer une figure de taille 4x4 pouces\n",
    "plt.figure(figsize=(4,4))\n",
    "# Afficher le nuage de points des prédictions et des valeurs réelles\n",
    "plt.scatter(Y_test[\"TARGET\"],prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "HrrMOhMDGCfj",
    "outputId": "c24addc1-9508-4273-96e9-abcec3efce6b"
   },
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# La dernière méthode que nous explorons est l'arbre de décision pour la regression\n",
    "\n"
   ],
   "metadata": {
    "id": "FgNqzwnCPay6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "reg= DecisionTreeRegressor(random_state=0)\n",
    "reg.fit(X_train[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Y_train[\"TARGET\"]))\n",
    "prediction = reg.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(Y_test[\"TARGET\"],prediction)"
   ],
   "metadata": {
    "id": "6fNmIRUeQB9o",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "outputId": "46f956da-6bea-4d71-b3f5-b6827678802b"
   },
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# On cherche maintenant à évaluer les différents modèles testés\n",
    "- la corrélation de Spearman,\n",
    "- le coefficient de détermination R2\n",
    "- l’erreur quadratique moyenne (RMSE)"
   ],
   "metadata": {
    "id": "boJH4x1vW64Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation de la regression linéaire\n",
    "print(\"\\nPour la regression linéaire :\")\n",
    "LR_predictions = LR.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']])) #Prédiction sur les données utilisées\n",
    "corr, pval = spearmanr(Y_test['TARGET'], LR_predictions) #Calcul de la corrélation de Spearman et de sa p-value\n",
    "print(\"Corrélation de Spearman:\", corr)\n",
    "r2 = r2_score(Y_test['TARGET'], LR_predictions)  #Calcul du coefficient de détermination R2 pour les prédictions\n",
    "print(\"Coefficient de détermination R2 :\", r2)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test['TARGET'], LR_predictions)) #Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE) pour les prédictions\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"P-value:\", pval)\n",
    "\n",
    "# Evaluation de la regression avec Ridge\n",
    "print(\"\\nPour la regression avec Ridge :\")\n",
    "ridge_predictions = ridge.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']])) #Prédiction sur les données utilisées\n",
    "corr_ridge, pval_ridge = spearmanr(Y_test['TARGET'], ridge_predictions) #Calcul de la corrélation de Spearman et de sa p-value\n",
    "print(\"Corrélation de Spearman:\", corr_ridge)\n",
    "r2_ridge = r2_score(Y_test['TARGET'], ridge_predictions) #Calcul du coefficient de détermination R2\n",
    "print(\"Coefficient de détermination R2 :\", r2)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(Y_test['TARGET'], ridge_predictions)) #Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE)\n",
    "print(\"RMSE:\", rmse_ridge)\n",
    "print(\"P-value:\", pval_ridge)\n",
    "\n",
    "# Evaluation de la regression avec Lasso\n",
    "print(\"\\nPour la regression avec Lasso :\")\n",
    "lasso_predictions = lasso.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']])) #Prédiction sur les données utilisées\n",
    "corr_lasso, pval_lasso = spearmanr(Y_test['TARGET'], lasso_predictions) #Calcul de la corrélation de Spearman et de sa p-value\n",
    "print(\"Corrélation de Spearman:\", corr_lasso)\n",
    "r2_lasso = r2_score(Y_test['TARGET'], lasso_predictions) #Calcul du coefficient de détermination R2\n",
    "print(\"Coefficient de détermination R2 :\", r2_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(Y_test['TARGET'], lasso_predictions)) #Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE)\n",
    "print(\"RMSE:\", rmse_lasso)\n",
    "print(\"P-value:\", pval_lasso)\n",
    "\n",
    "# Evaluation de KNN\n",
    "print(\"\\nPour KNN :\")\n",
    "knn_predictions = knn_model.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']])) #Prédiction sur les données utilisées\n",
    "corr_knn, pval_knn = spearmanr(Y_test['TARGET'], knn_predictions) #Calcul de la corrélation de Spearman et de sa p-value\n",
    "print(\"Corrélation de Spearman:\", corr_knn)\n",
    "r2_knn = r2_score(Y_test['TARGET'], knn_predictions) #Calcul du coefficient de détermination R2\n",
    "print(\"Coefficient de détermination R2 :\", r2_knn)\n",
    "rmse_knn = np.sqrt(mean_squared_error(Y_test['TARGET'], knn_predictions)) #Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE)\n",
    "print(\"RMSE:\", rmse_knn)\n",
    "print(\"P-value:\", pval_knn)\n",
    "\n",
    "# Evaluation de l'arbre de décision pour la regression\n",
    "print(\"\\nPour l'arbre de décision pour la regression:\")\n",
    "reg_predictions = reg.predict(pd.DataFrame(X_test[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']])) #Prédiction sur les données utilisées\n",
    "corr_reg, pval_reg = spearmanr(Y_test['TARGET'], reg_predictions) #Calcul de la corrélation de Spearman et de sa p-value\n",
    "print(\"Corrélation de Spearman:\", corr_reg)\n",
    "r2_reg = r2_score(Y_test['TARGET'], reg_predictions) #Calcul du coefficient de détermination R2\n",
    "print(\"Coefficient de détermination R2 :\", r2_reg)\n",
    "rmse_reg = np.sqrt(mean_squared_error(Y_test['TARGET'], reg_predictions)) #Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE)\n",
    "print(\"RMSE:\", rmse_reg)\n",
    "print(\"P-value:\", pval_reg)\n",
    "\n",
    "# Affichage des résultats\n",
    "plt.bar(['LR', 'Ridge', 'Lasso', 'KNN', 'Arbre de décision'], [corr, corr_ridge, corr_lasso, corr_knn, corr_reg])\n",
    "plt.title(\"Corrélation de Spearman\")\n",
    "plt.show()\n",
    "plt.bar(['LR', 'Ridge', 'Lasso', 'KNN', 'Arbre de décision'], [r2, r2_ridge, r2_lasso, r2_knn, r2_reg])\n",
    "plt.title(\"Coefficient de détermination R2\")\n",
    "plt.show()\n",
    "plt.bar(['LR', 'Ridge', 'Lasso', 'KNN', 'Arbre de décision'], [rmse, rmse_ridge, rmse_lasso, rmse_knn, rmse_reg])\n",
    "plt.title(\"RMSE\")\n",
    "plt.show()\n",
    "plt.bar(['LR', 'Ridge', 'Lasso', 'KNN', 'Arbre de décision'], [pval, pval_ridge, pval_lasso, pval_knn, pval_reg])\n",
    "plt.title(\"P-value\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QmMALyIbWyq2",
    "outputId": "9fa0d1d5-eb06-43e3-b096-8c02b0ad31b1"
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut observer que suivant les indicateurs P-value et RMSE, le modèle d'arbre de décision donne les meilleurs résultats par rapport à notre jeu de données.\n",
    "# On réalise donc maintenant la prédiction finale avec les DataNew_X en utilisant l'arbre de décision"
   ],
   "metadata": {
    "id": "Gnv_pjRiT51U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Créer une instance du modèle KNN avec 100 voisins\n",
    "knn_model = KNeighborsRegressor(n_neighbors=10)\n",
    "# Entraîner le modèle KNN en utilisant les données d'entraînement\n",
    "knn_model.fit(Data_X[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Data_Y[\"TARGET\"]))\n",
    "# Effectuer des prédictions sur les données de test\n",
    "prediction = knn_model.predict(pd.DataFrame(DataNew_X[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']]))\n",
    "print(prediction)\n",
    "\n",
    "# Créer une figure de taille 4x4 pouces\n",
    "plt.figure(figsize=(4,4))\n",
    "# Afficher le nuage de points des prédictions et des valeurs réelles\n",
    "# Générer des données aléatoires pour l'exemple\n",
    "# Créer l'histogramme\n",
    "plt.hist(prediction, bins=100)\n",
    "\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel('Valeurs')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution des valeurs')\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# Afficher le score total de notre représentation\n",
    "score = round(knn_model.score(Data_X[['DE_WINDPOW','DE_NET_EXPORT','DE_NET_IMPORT','DE_RESIDUAL_LOAD','FR_WINDPOW']],pd.DataFrame(Data_Y[\"TARGET\"])) * 100, 1)\n",
    "print(\"Score total:\",score)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jUZlp8bkUrCw",
    "outputId": "732f5df2-b0b1-49d8-d945-8e8ac1aeb7f2"
   },
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion:\n",
    "\n",
    "Tout au long de cette étude, on se rend compte que puisque nos valeurs sont très peu corrélées dès le départ, le résultat obtenu selon les méthodes utilisées varie radicalement. On a pu voir cela avec la régression linéaire ou la régression de Ridge qui donnait de résultat tout sauf concluant, tandis que le KNN avec l'arbre de décision donne des résultats bien plus concluant.\n",
    "\n",
    "Ce projet nous a donc permis de nous rendre compte que malgré les similitudes entre toutes les méthodes que nous avons étudiées en cours, certaine sont utiles dans certains cas bien précis. Nous avons ainsi tout au long de ce travail découvert dans quels cas laquelle est plus utile et permet d'avoir une meilleure représentation.\n",
    "\n",
    "Malheureusement, suite à un manque de communication de la part d'un de membre, le projet n'a pas pu être fini dans le temps imparti. Aussi, le manque de précision dans le sujet a été un problème majeur, nous bloquant pendant une longue partie du projet puisque nous ne savions pas réellement par où commencer."
   ],
   "metadata": {
    "id": "dJLW5NeSbHes"
   }
  }
 ]
}
